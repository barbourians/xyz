{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model Solution\n",
    "\n",
    "This notebook demonstrates logistic regression analysis to predict exam pass/fail based on hours of study.\n",
    "\n",
    "Converted from R script to Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('PassFail.csv')\n",
    "print(data.info())\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "print(\"Data types:\")\n",
    "print(data.dtypes)\n",
    "print(f\"\\nDataset shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = data[['Hours']]  # Features (needs to be 2D array)\n",
    "y = data['Pass']     # Target variable\n",
    "\n",
    "# Build and fit the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Display model coefficients\n",
    "print(\"Model Coefficients:\")\n",
    "print(f\"Intercept: {model.intercept_[0]:.4f}\")\n",
    "print(f\"Hours coefficient: {model.coef_[0][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make Predictions\n",
    "\n",
    "### Single Prediction\n",
    "What is the probability of passing with 2 hours of study?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_test = np.array([[2.0]])\n",
    "prob = model.predict_proba(hours_test)[:, 1]\n",
    "print(f\"Probability of passing with 2 hours: {prob[0]:.4f} ({prob[0]*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting for several values at the same time\n",
    "hours_multiple = np.array([[1.0], [1.5], [2.0], [2.5], [3.0], [3.5], [4.0], [4.5]])\n",
    "prob_pass = model.predict_proba(hours_multiple)[:, 1]\n",
    "\n",
    "print(\"Probabilities for multiple hour values:\")\n",
    "for hours, prob in zip(hours_multiple.flatten(), prob_pass):\n",
    "    print(f\"{hours} hours: {prob:.4f} ({prob*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Classification with Threshold\n",
    "\n",
    "Classification means converting probabilities into classes (making decisions).\n",
    "\n",
    "We need to define a threshold - let's use 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification with threshold 0.5:\")\n",
    "\n",
    "# Binary format (1/0)\n",
    "classifications_binary = np.where(prob_pass > 0.5, 1, 0)\n",
    "print(\"Binary (1/0):\", classifications_binary)\n",
    "\n",
    "# Boolean format\n",
    "classifications_bool = np.where(prob_pass > 0.5, True, False)\n",
    "print(\"Boolean:\", classifications_bool)\n",
    "\n",
    "# Text format\n",
    "classifications_text = np.where(prob_pass > 0.5, 'PASS', 'FAIL')\n",
    "print(\"Text:\", classifications_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. In-Sample Predictions and Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilities to pass the exam for in-sample values\n",
    "prob_pass_insample = model.predict_proba(X)[:, 1]\n",
    "print(\"In-sample probabilities:\")\n",
    "print(prob_pass_insample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(data['Hours'], prob_pass_insample, color='blue', alpha=0.6, s=50)\n",
    "plt.plot(data['Hours'], prob_pass_insample, 'b-', alpha=0.3)\n",
    "plt.xlabel('Hours of Study', fontsize=12)\n",
    "plt.ylabel('Probability of Passing', fontsize=12)\n",
    "plt.title('Logistic Regression: Hours vs Probability of Passing', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Predictions on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification of in-sample values\n",
    "classes = np.where(prob_pass_insample > 0.5, 1, 0)\n",
    "print(\"Predicted classes for in-sample data:\")\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predicted classes into the original dataset\n",
    "data['PredictedPass'] = classes\n",
    "print(\"Dataset with predictions:\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(data['Pass'], data['PredictedPass'])\n",
    "print(f\"Model Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# Alternative way to calculate accuracy\n",
    "accuracy_alt = np.sum(data['PredictedPass'] == data['Pass']) / len(data)\n",
    "print(f\"Alternative calculation: {accuracy_alt:.4f} ({accuracy_alt*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build confusion matrix\n",
    "cm = confusion_matrix(data['Pass'], data['PredictedPass'])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"                Predicted\")\n",
    "print(\"              0 (Fail)  1 (Pass)\")\n",
    "print(f\"Actual 0  [{cm[0,0]:>8}  {cm[0,1]:>8}]\")\n",
    "print(f\"Actual 1  [{cm[1,0]:>8}  {cm[1,1]:>8}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Performance Metrics\n",
    "\n",
    "Calculate True Positives, False Positives, True Negatives, and False Negatives manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics manually\n",
    "TP = np.sum((data['PredictedPass'] == data['Pass']) & (data['Pass'] == 1))\n",
    "TN = np.sum((data['PredictedPass'] == data['Pass']) & (data['Pass'] == 0))\n",
    "FP = np.sum((data['PredictedPass'] != data['Pass']) & (data['Pass'] == 0))\n",
    "FN = np.sum((data['PredictedPass'] != data['Pass']) & (data['Pass'] == 1))\n",
    "\n",
    "print(\"Performance Metrics:\")\n",
    "print(f\"True Positives (TP):  {TP}\")\n",
    "print(f\"True Negatives (TN):  {TN}\")\n",
    "print(f\"False Positives (FP): {FP}\")\n",
    "print(f\"False Negatives (FN): {FN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rates\n",
    "TPR = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "FPR = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "\n",
    "print(f\"True Positive Rate (Sensitivity): {TPR:.4f}\")\n",
    "print(f\"False Positive Rate: {FPR:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Loading and exploring data\n",
    "2. Building a logistic regression model\n",
    "3. Making predictions with the model\n",
    "4. Classifying probabilities using a threshold\n",
    "5. Visualising the model predictions\n",
    "6. Evaluating model performance using accuracy and confusion matrix\n",
    "7. Calculating performance metrics (TP, TN, FP, FN, TPR, FPR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
